# -*- coding: utf-8 -*-
"""mjproject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jHW64dg5MoHDr3IxbE8TNt0wqG5mXmOI
"""

#1. Create a dataframe

import pandas as pd
df = pd.read_csv('/content/heart_2020_cleaned.csv.zip')
df

#2.Exploratory Data Analysis

#Details about the columns of the dataset
df.info()

#View the number of rows and columns
df.shape

#Distribution of data
df.describe()

#Check missing values
df.isnull().sum()

#3. Data Visualisation
import matplotlib.pyplot as plt
import seaborn as sns

#Numerical feature distribution
col = ['BMI','PhysicalHealth','MentalHealth','SleepTime']

for i in range(0,len(col)):
  plt.figure(figsize=(10,1),dpi=80)
  sns.boxplot(x=col[i],y=df['HeartDisease'],data=df,orient="h")
  plt.title(col[i]+" Distribution",fontweight='bold')
  plt.show()

#Categorial feature distribution
binary_cols = ['HeartDisease','Sex','Smoking','AlcoholDrinking','Stroke','Asthma', 'DiffWalking','PhysicalActivity','KidneyDisease','SkinCancer']
for i in range(1,len(binary_cols)):
  fig = plt.figure(figsize=(8,4), dpi=80)
  
  #Plot distribution of people with heart disease
  ax1=plt.subplot(1,2,1)
  df[df['HeartDisease'] == 'Yes'].groupby(df[binary_cols[i]]).HeartDisease.count().plot(kind='pie', autopct='%.1f%%', labeldistance=None,wedgeprops = { 'linewidth' : 7, 'edgecolor' : 'white', 'width':0.35 })
  plt.title("With HeartDisease")

  #Plot distribution of people without heart disease
  ax2=plt.subplot(1,2,2)
  df[df['HeartDisease'] == 'No'].groupby(df[binary_cols[i]]).HeartDisease.count().plot(kind='pie', autopct='%.1f%%', labeldistance=None,wedgeprops = { 'linewidth' : 7, 'edgecolor' : 'white', 'width':0.35 })
  plt.title("Without HeartDisease")

  
  plt.suptitle("Patient with/without Heart Disease distribution by " + binary_cols[i] + " status", fontweight='bold')

  handles, labels = ax1.get_legend_handles_labels()
  leg = fig.legend(handles, labels, loc = 'upper right', fancybox=True)
  plt.show()

cat_cols = ['AgeCategory','Race','Diabetic','GenHealth']


for i in range(0, len(cat_cols)):
    crosstb = pd.crosstab(df[cat_cols[i]], df.HeartDisease)
    crosstb['without_hd_percent'] = crosstb['No'] / (crosstb['No'] + crosstb['Yes'])
    crosstb['with_hd_percent'] = crosstb['Yes'] / (crosstb['No'] + crosstb['Yes'])
    
    crosstb = crosstb.drop(['Yes', 'No'], axis = 1)
    
    crosstb.plot(kind='barh')
    sns.despine()
    labels = ["without hd","with hd"]
    plt.gcf().set_size_inches(12, 4)
    plt.xticks(rotation = 45)
    plt.legend(labels=labels)
    plt.title("Percentage of patient with/ without Heart Disease by " + cat_cols[i], fontweight='bold')
    plt.show()

#Encoding the non-numerical features
datum = df.drop(["BMI", "PhysicalHealth", "MentalHealth", "SleepTime"], axis = 1)
from sklearn.preprocessing import LabelEncoder
Encoder_datum = LabelEncoder()
for col in datum.columns:
  datum [col] = Encoder_datum.fit_transform (datum[col])

#Re-adding the numerical features
datum["BMI"] = df["BMI"]
datum["PhysicalHealth"] = df["PhysicalHealth"]
datum["MentalHealth"] = df["MentalHealth"]
datum["SleepTime"] = df["SleepTime"]

datum.head(5)

#4. Take input and output values
x = datum.iloc[:,1:18]
y = datum.iloc[:,0]

#5. Train and test variables
from sklearn.model_selection import train_test_split 
x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.2, random_state= 2)

#6. Normalization/Scaling
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.fit_transform(x_test)

#7. Apply a classifier/regressor/clusterer
from sklearn.linear_model import LogisticRegression
model = LogisticRegression()

#8. Fitting of the model
model.fit(x_train,y_train)

#9. Predictor variable
y_pred = model.predict(x_test)

#10. Accuracy calculation
from sklearn.metrics import accuracy_score
accuracy_score(y_pred,y_test)*100

#Individual prediction
model.predict([[0,0,0,1,0,4,5,0,1,4,0,0,0,23.71,28.0,0.0,8.0]])

#The above code compiled in a single cell
#EDA, Visualisation and Logistic Regression

#1. Create a dataframe

import pandas as pd
df = pd.read_csv('/content/heart_2020_cleaned.csv.zip')
print('DATAFRAME :')

print(df)
print('\n')

#2.Exploratory Data Analysis

#Details about the columns of the dataset
print('Column Details :')
print(df.info())
print('\n')

#View the number of rows and columns
print('Rows and columns =',df.shape)
print('\n')

#Check missing values
print('Details of missing values :')
print(df.isnull().sum())
print('\n')

#3. Data Visualisation
import matplotlib.pyplot as plt
import seaborn as sns
print('VISUALISATION :')

#Numerical feature distribution
col = ['BMI','PhysicalHealth','MentalHealth','SleepTime']

for i in range(0,len(col)):
  plt.figure(figsize=(10,1),dpi=80)
  sns.boxplot(x=col[i],y=df['HeartDisease'],data=df,orient="h")
  plt.title(col[i]+" Distribution",fontweight='bold')
  plt.show()
  
#Categorial feature distribution
binary_cols = ['HeartDisease','Sex','Smoking','AlcoholDrinking','Stroke','Asthma', 'DiffWalking','PhysicalActivity','KidneyDisease','SkinCancer']
for i in range(1,len(binary_cols)):
  fig = plt.figure(figsize=(8,4), dpi=80)
  
  #Plot distribution of people with heart disease
  ax1=plt.subplot(1,2,1)
  df[df['HeartDisease'] == 'Yes'].groupby(df[binary_cols[i]]).HeartDisease.count().plot(kind='pie', autopct='%.1f%%', labeldistance=None,wedgeprops = { 'linewidth' : 7, 'edgecolor' : 'white', 'width':0.35 })
  plt.title("With HeartDisease")

  #Plot distribution of people without heart disease
  ax2=plt.subplot(1,2,2)
  df[df['HeartDisease'] == 'No'].groupby(df[binary_cols[i]]).HeartDisease.count().plot(kind='pie', autopct='%.1f%%', labeldistance=None,wedgeprops = { 'linewidth' : 7, 'edgecolor' : 'white', 'width':0.35 })
  plt.title("Without HeartDisease")

  
  plt.suptitle("Patient with/without Heart Disease distribution by " + binary_cols[i] + " status", fontweight='bold')

  handles, labels = ax1.get_legend_handles_labels()
  leg = fig.legend(handles, labels, loc = 'upper right', fancybox=True)
  plt.show()

cat_cols = ['AgeCategory','Race','Diabetic','GenHealth']
for i in range(0, len(cat_cols)):
    crosstb = pd.crosstab(df[cat_cols[i]], df.HeartDisease)
    crosstb['without_hd_percent'] = crosstb['No'] / (crosstb['No'] + crosstb['Yes'])
    crosstb['with_hd_percent'] = crosstb['Yes'] / (crosstb['No'] + crosstb['Yes'])
    
    crosstb = crosstb.drop(['Yes', 'No'], axis = 1)
    
    crosstb.plot(kind='barh')
    sns.despine()
    labels = ["without hd","with hd"]
    plt.gcf().set_size_inches(12, 4)
    plt.xticks(rotation = 45)
    plt.legend(labels=labels)
    plt.title("Percentage of patient with/ without Heart Disease by " + cat_cols[i], fontweight='bold')
    plt.show()

#Encoding the non-numerical features
datum = df.drop(["BMI", "PhysicalHealth", "MentalHealth", "SleepTime"], axis = 1)
from sklearn.preprocessing import LabelEncoder
Encoder_datum = LabelEncoder()
for col in datum.columns:
  datum [col] = Encoder_datum.fit_transform (datum[col])

#Re-adding the numerical features
datum["BMI"] = df["BMI"]
datum["PhysicalHealth"] = df["PhysicalHealth"]
datum["MentalHealth"] = df["MentalHealth"]
datum["SleepTime"] = df["SleepTime"]

print('\n','Encoded Dataset :')
print(datum.head(5))
print('\n')

#4. Take input and output values
x = datum.iloc[:,1:18]
y = datum.iloc[:,0]

#5. Train and test variables
from sklearn.model_selection import train_test_split 
x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.2, random_state= 2)

#6. Normalization/Scaling
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.fit_transform(x_test)

#7. Apply a classifier/regressor/clusterer
from sklearn.linear_model import LogisticRegression
model = LogisticRegression()

#8. Fitting of the model
model.fit(x_train,y_train)

#9. Predictor variable
y_pred = model.predict(x_test)

#10. Accuracy calculation
from sklearn.metrics import accuracy_score
print('Accuracy of the model =',accuracy_score(y_pred,y_test)*100)
print('\n')

#Individual prediction
print('Individual Prediction Result =',model.predict([[0,0,0,1,0,4,5,0,1,4,0,0,0,23.71,28.0,0.0,8.0]]))

